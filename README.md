# AutomationProject
Shared repository for working on the requirements of Monash Universities TRC3000. The folder 'ProjectTests' contains the code for the attention communication aid for visually impaired users that the team development over the semester. Gaze and head position are important non-verbal communicators of attention between interlocutors. Without this information, visually impaired people may struggle to construe if they are the intended recipient of speech and may suffer from cognitive overload. Our device overcomes these problems by using face recognition, gaze direction, head position and face matching algorithms to calculate an attention score for each person in the camera field of view. The person with highest attention score is tracked as they move around the user provided they are deemed 'reasonably attentive'. The position and relative attention level of the most attentive speaker is then communicated to the user using five vibrating motor disks spaced evenly around the user's head. An example of the operation of this code and the final device can be found on the following link: https://drive.google.com/file/d/1DSPC9W9zh1wvVv0oMKSffQhIrTEfQpFo/view?usp=sharing. More details of the device are contained in files 'ProjectProposal.pdf', 'ProgressReport.pdf' and 'FinalReport.pdf'. 
